A small language model using the bleeding edge in things and stuff.

# The things:
Tensor product attention: [Tensor Product Attention is All You Need](https://arxiv.org/abs/2501.06425)

(Optional -- used in the Tensor product attention, hard to stabilize)
Lightning attention: [Lightning Attention 1](https://arxiv.org/abs/2405.17381) || [Lightning Attention 2](https://arxiv.org/abs/2401.04658) || [Github](https://github.com/OpenNLPLab/lightning-attention)

Differential Attention: [Differential Transformer](https://arxiv.org/abs/2410.05258) 

Expanded gating functions: [Expanded Gating Ranges Improve Activation Functions](https://arxiv.org/pdf/2405.20768)

Distributed Shampoo Optimizer: [Distributed Shampoo Paper](https://arxiv.org/abs/2309.06497) || [Distributed Shampoo Github](https://github.com/facebookresearch/optimizers/blob/main/distributed_shampoo/README.md)

Cut Cross Entropy: [Cut Cross Entropy](https://arxiv.org/abs/2411.09009) || [Github](https://github.com/apple/ml-cross-entropy)
